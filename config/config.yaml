# Master Configuration File
# This is the default configuration loaded by train_baseline.py
# All settings can be overridden via command-line arguments

# ============================================================================
# Dataset Selection
# ============================================================================
dataset:
  # Primary dataset for training/testing
  name: "MR2"  # Options: AMG, DGM4, FineFake, MMFakeBench, MR2

  # Language filter (for multilingual datasets like MR2)
  language: zh  # Options: null (all), "en", "zh"

  # Label handling
  exclude_unverified: false  # For MR2: whether to exclude label=2 (unverified)

  # Data paths
  data_root: "data"
  train_split: "train"
  val_split: "val"
  test_split: "test"

  # Preprocessing
  max_text_length: 512
  use_ocr: true  # Whether to include OCR text

# ============================================================================
# Model Configuration
# ============================================================================
model:
  # Encoder settings
  text_model: "xlm-roberta-base"
  image_model: "openai/clip-vit-base-patch16"

  # Architecture dimensions (automatically inferred from encoders)
  hidden_dim: 768  # CLIP-ViT-Base/16 hidden dimension

  # Fusion settings
  num_fusion_layers: 3
  num_heads: 8  # Number of attention heads in fusion layers

  # Evidence fusion (advanced feature)
  use_evidence: false
  caption_max_length: 128  # Max length for evidence captions

  # CLIP unfreezing strategy
  unfreeze_clip_layers: 3  # Number of last CLIP layers to unfreeze (0=all frozen)

  # Classifier settings
  classifier_hidden_dim: 512  # Hidden dimension in final classifier

  # Regularization
  dropout: 0.3

# ============================================================================
# Training Configuration
# ============================================================================
training:
  # Basic settings
  num_epochs: 10
  batch_size: 32

  # Optimizer
  optimizer: "adamw"
  learning_rate: 2.0e-5      # For fusion/text/classifier layers
  clip_lr: 1.0e-6            # For unfrozen CLIP layers (layered LR)
  weight_decay: 0.1

  # Learning rate scheduler
  warmup_ratio: 0.1
  max_grad_norm: 1.0  # Gradient clipping

  # Mixed precision training (FP16)
  mixed_precision: true  # Recommended: 2x faster, half memory

  # Loss function
  loss_fn: "cross_entropy"

# ============================================================================
# Experiment Configuration
# ============================================================================
experiment:
  # Random seed for reproducibility
  seed: 42

  # Device settings
  device: "cuda"
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2

  # Output directories
  output_dir: "outputs"

  # Logging intervals
  logging_steps: 50  # Log training metrics every N steps

  # Evaluation settings
  eval_strategy: "epoch"  # Options: "epoch" (eval after each epoch), "steps" (eval every N steps)
  eval_steps: 500  # Only used if eval_strategy="steps"
  eval_metric: "f1"  # Metric to select best model (f1 = macro F1)

  # Early stopping
  early_stopping: true  # Enable early stopping
  patience: 3  # Stop if no improvement for N epochs

  # Checkpointing settings
  save_strategy: "epoch"  # Options: "epoch" (save after each epoch), "steps" (save every N steps)
  save_steps: 500  # Only used if save_strategy="steps"
  save_total_limit: 2  # Keep only N best checkpoints (based on eval_metric)
  save_best_only: true  # Only save when eval_metric improves